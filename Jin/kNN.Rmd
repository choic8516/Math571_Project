---
title: "kNN"
author: "Jingwei Li"
date: "April 19, 2018"
output: html_document
---

```{r setup, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

## Kaggle data
### Load cleaned kaggle data
```{r}
library(xlsx)
file <- file.path('../Connor/Complete Data/kaggle_headlines_scored_classified.xlsx')
k_data <- read.xlsx(file = file, sheetIndex = 1, stringsAsFactors = F)
k_data$Date <- as.Date(k_data$Date)
k_data$Label <- as.factor(k_data$Label)
```

### Divide Train and Test
Pick Jan 1, 2016 as the borderline of two sets.
```{r}
k_train <- k_data[k_data$Date < as.Date("2016-01-01"),]
k_test <- k_data[k_data$Date >= as.Date("2016-01-01"),]
stopifnot((nrow(k_train) + nrow(k_test)) == nrow(k_data))
```

### kNN
Remove target varibale and date from train set
```{r}
library(class)
library(caret)
set.seed(999)
targetVars <- c("Label")
xVars <- c("Very.Negative", "Negative", "Neutral", "Postive", "Very.Positive")
k_train_label <- k_train[, targetVars]
k_test_label <- k_test[, targetVars]
k_train_xVars <- k_train[, xVars]
k_test_xVars <- k_test[, xVars]

knn_function <- function(k_value){
        temp_knn <- knn(train = k_train_xVars, test = k_test_xVars, cl = k_train_label, k = k_value)
        temp_knn_cm <- confusionMatrix(reference = k_test_label, data = temp_knn)
        return(temp_knn_cm$overall[1])
}

opt_k <- which.max(lapply(seq(1,100), knn_function))
opt_acc <- knn_function(opt_k)
```
It shows that the optimal k-value can be picked from 14 to 18. The accuracy is around 56.3%.

## NYT data
### Load cleaned kaggle data
NA is removed for kNN model. NA data shows up on weekends.
```{r}
library(data.table)
file <- file.path('../Connor/Complete Data/classified_scores_&_stock_movement_1.csv')
nyt_data <- as.data.frame(fread(file = file))
nyt_data$Date <- as.Date(nyt_data$Date)
nyt_data$Direction <- as.factor(nyt_data$Direction)
nyt_data_rm <- na.omit(nyt_data)
```

### Divide Train and Test
Pick Jan 1, 2014 as the borderline of two sets.
```{r}
nyt_train <- nyt_data_rm[nyt_data_rm$Date < as.Date("2014-01-01"),]
nyt_test <- nyt_data_rm[nyt_data_rm$Date >= as.Date("2014-01-01"),]
stopifnot((nrow(nyt_train) + nrow(nyt_test)) == nrow(nyt_data_rm))
```

### kNN
```{r}
library(class)
library(caret)
targetVars <- c("Direction")
xVars <- c("Very.Negative", "Negative", "Neutral", "Postive", "Very.Positive")
nyt_train_label <- nyt_train[, targetVars]
nyt_test_label <- nyt_test[, targetVars]
nyt_train_xVars <- nyt_train[, xVars]
nyt_test_xVars <- nyt_test[, xVars]

knn_function2 <- function(k_value){
        temp_knn <- knn(train = nyt_train_xVars, test = nyt_test_xVars, cl = nyt_train_label, k = k_value)
        temp_knn_cm <- confusionMatrix(reference = nyt_test_label, data = temp_knn)
        return(temp_knn_cm$overall[1])
}

k_range <- seq(1,300)
result_list <- lapply(k_range, knn_function2)
plot(k_range, result_list, type = "l")
opt_k <- which.max(result_list)
opt_acc <- knn_function2(opt_k)
```
The plot shows that we have two possible optimal k-value range. First one is around 3 and second one is around 160. Both of them have about 51% accuracy roughly. It's just slightly better than tosing a coin.

### improve