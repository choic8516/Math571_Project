"0","library(xlsx)"
"0","library(tidyverse)"
"0","library(SentimentAnalysis)"
"0","data_1 <- read.xlsx(""nyt_headlines.xls"", sheetIndex = 1,stringsAsFactors=FALSE)"
"0","subset_of_data_1 <- data_1[1:2,-1]"
"0","convert_to_score <- function(df) {"
"0","        sentiment <- analyzeSentiment(df)"
"0","        sentiment$SentimentHE # I chose here Harvard General Inquirer lexicon but you can also choose other lexicons. There are I think 3 other ones including Loughran and McDonald lexicon"
"0","}"
"0","# this following operation takes about 20 seconds for my laptop. I feel like it takes little too long. "
"0","subset_of_data_1[] <- lapply(subset_of_data_1, convert_to_score)"
"0","subset_of_data_1"
