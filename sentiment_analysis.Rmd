---
title: "Math571_project"
output: html_document
---

# Converting headlines into scores (using SentimentAnalysis package)
```{r}
library(xlsx)
library(tidyverse)
library(SentimentAnalysis)

file <- "nyt_headlines_2005_2008_2016_2017.xlsx"
# file <- "nyt_headlines.xls"
data <- read.xlsx(file = file, sheetIndex = 1, stringsAsFactors=FALSE)

#I added a restriction to the analyeSentiment function so it only calculates
#with the GI dictionary, wich makes it much more efficient
convert_to_score <- function(df) {
        sentiment <- analyzeSentiment(df,
                              rules=list("SentimentGI"=list(ruleSentiment, 
                                                            loadDictionaryGI())))
        return(sentiment$SentimentGI) 
}

# this following operation takes about 20 seconds for my laptop. I feel like it takes little too long. 
data_sentiment <- lapply(data[,-1], convert_to_score)
data_sentiment <- as.data.frame(data_sentiment)
head(data_sentiment)
result <- cbind(data[,1], data_sentiment)
names(result)[1] <- "pub_date"
head(result)
tail(result)
#write.csv(data_sentiment,"ignore_scores2.csv")
```


